{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wisconsin Breast Cancer Study\n",
    "## Dataset\n",
    "- [Here](https://s3-us-west-2.amazonaws.com/ga-dat-2015-suneel/datasets/breast-cancer.csv) is the dataset.\n",
    "- [Here](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names) is a description of the data. Ignore column 0 as it is merely the ID of a patient record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/jam3jam/Downloads/breast_cancer.csv', sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9    ...        22     23      24      25      26      27      28  \\\n",
       "0  0.14710   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "1  0.07017   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "2  0.12790   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "3  0.10520   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "4  0.10430   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "       29      30       31  \n",
       "0  0.2654  0.4601  0.11890  \n",
       "1  0.1860  0.2750  0.08902  \n",
       "2  0.2430  0.3613  0.08758  \n",
       "3  0.2575  0.6638  0.17300  \n",
       "4  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VERIFY THAT DATASET IS OF PROPER DIMENSION\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Separate the data into feature and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIAL FEATURE WRANGLING AND PREPROCESSING\n",
    "# COLUMN 0 IS NOT RELEVANT, COLUMN 1 IS y, THE REST COMPRISE THE FEATURE MATRIX X\n",
    "# CREATE BINARY FACTORS FOR THE y FOR THE LOGISTIC REGRESSION PREPARATION\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df.loc[:, 1].values\n",
    "X = df.loc[:, 2:].values\n",
    "\n",
    "# INSTANTIATE LABELENCODER CLASS\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y\n",
    "y = pd.DataFrame(df[1].map({'B':0, 'M':1}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Logistic Regression and evaluate using cross_val_score and 5 folds.\n",
    "- What is the mean accuracy?\n",
    "- What is the standard deviation of accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('INITIAL MODEL ACCURACY (NO Cross Validation: ', 0.95957820738137078)\n",
      "('CV 5-FOLD Scores: ', array([ 0.93043478,  0.93913043,  0.97345133,  0.95575221,  0.96460177]))\n",
      "('CV 5-FOLD Mean Accuracy', 0.9526741054251634)\n",
      "('CV 5-FOLD Standard Deviation of Accuracy', 0.015883673194698897)\n"
     ]
    }
   ],
   "source": [
    "# CREATE MODEL (LOGISTIC REGRESSION CONSISTENT WITH ACTUAL STUDY) AND EVALUATE USING CROSS_VAL_SCORE AND 5 FOLDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# l2 - NON-SPARSE REGULARIZATION INVOKED - INSTANTIATE LOGISTIC REGRESSION WITH C=1 PARAMETER\n",
    "lr = LogisticRegression(penalty = 'l2', C=1)\n",
    "lr.fit(X, y)\n",
    "print('INITIAL MODEL ACCURACY (NO Cross Validation: ', lr.score(X, y))\n",
    "\n",
    "\n",
    "# WITH 5-FOLD CROSS VALIDATION (WE ARE TOLD TO USE CROSS_VAL_SCORE)\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "# CV VIA REUSED INSTANTIATED LR MODEL ABOVE \n",
    "scores = cross_validation.cross_val_score(lr, X, y,scoring='accuracy', cv=5)\n",
    "print('CV 5-FOLD Scores: ', scores)\n",
    "print('CV 5-FOLD Mean Accuracy', scores.mean() )\n",
    "print('CV 5-FOLD Standard Deviation of Accuracy', scores.std() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get a classification report to identify type 1, type 2 errors.\n",
    "- Use train_test_split to run your model once, with a test size of 0.33\n",
    "- Make predictions on the test set\n",
    "- Compare the predictions to the answers to determine the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9521\n",
      "Total Misclassified Samples (sum off-diagonals): 9\n",
      "[[119   4]\n",
      " [  5  60]]\n",
      "Confusion Matrix for Type I and Type II Error\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAEKCAYAAADw9/tHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+v6pLrVVigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bc9cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.96      0.97      0.96       123\n",
      "  Malignant       0.94      0.92      0.93        65\n",
      "\n",
      "avg / total       0.95      0.95      0.95       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DIVIDE DATASET INTO SEPARATE TRAINING DATASET - TEST SIZE SET TO 0.33 - TRAIN_TEST_SPLIT\n",
    "\n",
    "# DIVIDE DATASET INTO SEPARATE TRAINING DATASET - TEST SIZE SET TO 0.33 - TRAIN_TEST_SPLIT\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=1)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# print lr.score(X_test, y_test)\n",
    "# MAKE A PREDICTION ON THE TEST SET AS DIRECTED\n",
    "y_pred = lr.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))\n",
    "\n",
    "# COMPARE THE PREDICTIONS TO THE ANSWERS TO DETERMINE THE CLASSIFICATION REPORT\n",
    "print('Total Misclassified Samples (sum off-diagonals): %d' % (y_test != y_pred).sum())\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.matshow(confmat, cmap=plt.cm.Greens, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i,\n",
    "            s=confmat[i, j],\n",
    "            va='center', ha='center')\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "print('Confusion Matrix for Type I and Type II Error')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Benign', 'Malignant']\n",
    "y_true = y_test\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scale the data and see if that improves the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled/Standardized Improved Test Accuracy: 0.9681\n"
     ]
    }
   ],
   "source": [
    "# STANDARDIZE COLUMNS OF THE DATASET BEFORE FEEDING THEM TO THE LINEAR CLASSIFIER\n",
    "# CREATE PIPELINE FOR TWO-STEP PROCESS\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([ ('scl', StandardScaler()), ('clf', LogisticRegression(random_state=1)) ])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "print('Scaled/Standardized Improved Test Accuracy: %.4f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tune the model using automated parametric grid search via LogisticRegressionCV. Explain your intution behind what is being tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Best Score: 0.9816\n",
      "Grid Search Best Parameter for C: \n",
      "{'clf__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# TUNE THE MODEL USING AUTOMATED GRID SEARCH VIA 'LogisticRegressionCV' - NOTE GridSearchCV has been implemented\n",
    "# below since LogisticRegressionCV has been deprecated\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'clf__C': param_range}]\n",
    "\n",
    "# USING PIPE_LR FROM ABOVE WITH SCALED/STANDARDIZED VALUES\n",
    "# INSTANTIATE\n",
    "gs = GridSearchCV(estimator=pipe_lr, param_grid=param_grid, scoring='accuracy', cv=10,n_jobs=-1)\n",
    "# PERFORM GRIDSEARCH\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print('Grid Search Best Score: %.4f' % gs.best_score_)\n",
    "print('Grid Search Best Parameter for C: ')\n",
    "print gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What should we do to prevent overfitting so our model generalizes well to the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What was the best C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$J(w) =  \\sum_{i=1}^n\\left[ \\left( -y^{(i)}*log(\\phi(z^{(i)}) ) - (1-y^{(i)}) \\right) * log(1 - \\phi(z^{(i)})) \\right] + \\frac{\\lambda}{2} \\parallel w  \\parallel ^2$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$ C = \\frac{1}{\\lambda}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "display(Math(r'J(w) =  \\sum_{i=1}^n\\left[ \\left( -y^{(i)}*log(\\phi(z^{(i)}) ) - (1-y^{(i)}) \\right) * log(1 - \\phi(z^{(i)})) \\right] + \\frac{\\lambda}{2} \\parallel w  \\parallel ^2'))\n",
    "display(Math(r' C = \\frac{1}{\\lambda}'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
