{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will explore several datasets with SVMs. The assets folder contains several datasets (in order of complexity):\n",
    "\n",
    "1. Breast cancer\n",
    "- Spambase\n",
    "- Car evaluation\n",
    "- Mushroom\n",
    "\n",
    "For each of these a `.names` file is provided with details on the origin of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Breast Cancer\n",
    "\n",
    "\n",
    "\n",
    "## 1.a: Load the Data\n",
    "Use `pandas.read_csv` to load the data and assess the following:\n",
    "- Are there any missing values? (how are they encoded? do we impute them?)\n",
    "- Are the features categorical or numerical?\n",
    "- Are the values normalized?\n",
    "- How many classes are there in the target?\n",
    "\n",
    "Perform what's necessary to get to a point where you have a feature matrix `X` and a target vector `y`, both with only numerical entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b: Model Building\n",
    "\n",
    "- What's the baseline for the accuracy?\n",
    "- Initialize and train a linear svm. What's the average accuracy score with a 3-fold cross validation?\n",
    "- Repeat using an rbf classifier. Compare the scores. Which one is better?\n",
    "- Are your features normalized? if not, try normalizing and repeat the test. Does the score improve?\n",
    "- What's the best model?\n",
    "- Print a confusion matrix and classification report for your best model using:\n",
    "        train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "\n",
    "**Check** to decide which model is best, look at the average cross validation score. Are the scores significantly different from one another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Are there more false positives or false negatives? Is this good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c: Feature Selection\n",
    "\n",
    "Use any of the strategies offered by `sklearn` to select the most important features.\n",
    "\n",
    "Repeat the cross validation with only those 5 features. Does the score change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d: Learning Curves\n",
    "\n",
    "Learning curves are useful to study the behavior of training and test errors as a function of the number of datapoints available.\n",
    "\n",
    "- Plot learning curves for train sizes between 10% and 100% (use StratifiedKFold with 5 folds as cross validation)\n",
    "- What can you say about the dataset? do you need more data or do you need a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.e: Grid Ssearch\n",
    "\n",
    "Use the grid_search function to explore different kernels and values for the C parameter.\n",
    "\n",
    "- Can you improve on your best previous score?\n",
    "- Print the best parameters and the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Now that you've completed steps 1.a through 1.e it's time to tackle some harder datasets. But before we do that, let's encapsulate a few things into functions so that it's easier to repeat the analysis.\n",
    "\n",
    "## 2.a: Cross Validation\n",
    "Implement a function `do_cv(model, X, y, cv)` that does the following:\n",
    "- Calculates the cross validation scores\n",
    "- Prints the model\n",
    "- Prints and returns the mean and the standard deviation of the cross validation scores\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.b: Confusion Matrix and Classification report\n",
    "Implement a function `do_cm_cr(model, X, y, names)` that automates the following:\n",
    "- Split the data using `train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)`\n",
    "- Fit the model\n",
    "- Prints confusion matrix and classification report in a nice format\n",
    "\n",
    "**Hint:** names is the list of target classes\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.c: Learning Curves\n",
    "Implement a function `do_learning_curve(model, X, y, sizes)` that automates drawing the learning curves:\n",
    "- Allow for sizes input\n",
    "- Use 5-fold StratifiedKFold cross validation\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.d: Grid Search\n",
    "Implement a function `do_grid_search(model, parameters)` that automates the grid search by doing:\n",
    "- Calculate grid search\n",
    "- Print best parameters\n",
    "- Print best score\n",
    "- Return best estimator\n",
    "\n",
    "\n",
    "> Answer: see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "Using the functions above, analyze the Spambase dataset.\n",
    "\n",
    "Notice that now you have many more features. Focus your attention on step C => feature selection\n",
    "\n",
    "- Load the data and get to X, y\n",
    "- Select the 15 best features\n",
    "- Perform grid search to determine best model\n",
    "- Display learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Repeat steps 1.a - 1.e for the car dataset. Notice that now features are categorical, not numerical.\n",
    "- Find a suitable way to encode them\n",
    "- How does this change our modeling strategy?\n",
    "\n",
    "Also notice that the target variable `acceptability` has 4 classes. How do we encode them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "Repeat steps 1.a - 1.e for the mushroom dataset. Notice that now features are categorical, not numerical. This dataset is quite large.\n",
    "- How does this change our modeling strategy?\n",
    "- Can we use feature selection to improve this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
