{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors classification walkthrough\n",
    "\n",
    "In this notebook we are going to look at how the kNN algorithm classifies malignant vs. benign tumor category in the Wisconsin breast cancer dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# seaborn is a nice package for plotting, but you have to use pip to install\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load in the dataset\n",
    "\n",
    "Path is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bcw = pd.read_csv('../assets/datasets/wdbc.data', header=None, index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Assign the columns\n",
    "\n",
    "The attributes below will be the columns of the dataset.\n",
    "\n",
    "      Attribute                     \n",
    "   --------------------------------------------\n",
    "   1. Sample code number [subject ID]\n",
    "   2. Class\n",
    "   3. Cell nucleus mean radius\n",
    "   4. Cell nucleus SE radius\n",
    "   5. Cell nucleus worst radius\n",
    "   6. Texture mean\n",
    "   7. Texture SE\n",
    "   8. Texture worst\n",
    "   9. Perimeter mean\n",
    "   10. Perimeter SE\n",
    "   11. Perimeter worst\n",
    "   12. Area mean\n",
    "   13. Area SE\n",
    "   14. Area worst\n",
    "   15. Smoothness mean\n",
    "   16. Smoothness SE\n",
    "   17. Smoothness worst\n",
    "   18. Compactness mean\n",
    "   19. Compactness SE\n",
    "   20. Compactness worst\n",
    "   21. Concavity mean\n",
    "   22. Concavity SE\n",
    "   23. Concavity worst\n",
    "   24. Concave points mean\n",
    "   25. Concave points SE\n",
    "   26. Concave points worst\n",
    "   27. Symmetry mean\n",
    "   28. Symmetry SE\n",
    "   29. Symmetry worst\n",
    "   30. Fractal dimension mean\n",
    "   31. Fractal dimension SE\n",
    "   32. Fractal dimension worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are taken from the dataset info file. \n",
    "\n",
    "For more information check out the information file:\n",
    "\n",
    "`../assets/datasets/wdbc.names`\n",
    "\n",
    "You can open it with a text editor of your choice.\n",
    "\n",
    "Create an array with the column names and assign them as the header when loading the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = ['id','malignant',\n",
    "                'nucleus_mean','nucleus_se','nucleus_worst',\n",
    "                'texture_mean','texture_se','texture_worst',\n",
    "                'perimeter_mean','perimeter_se','perimeter_worst',\n",
    "                'area_mean','area_se','area_worst',\n",
    "                'smoothness_mean','smoothness_se','smoothness_worst',\n",
    "                'compactness_mean','compactness_se','compactness_worst',\n",
    "                'concavity_mean','concavity_se','concavity_worst',\n",
    "                'concave_pts_mean','concave_pts_se','concave_pts_worst',\n",
    "                'symmetry_mean','symmetry_se','symmetry_worst',\n",
    "                'fractal_dim_mean','fractal_dim_se','fractal_dim_worst']\n",
    "\n",
    "bcw.columns = column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check out the dataset information\n",
    "\n",
    "Print out the head and the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Recode the class field to be 0 vs. 1\n",
    "\n",
    "The malignant class field is coded as \"B\" for benign and \"M\" as malignant. \n",
    "\n",
    "It is best to recode this to a binary integer for classification, with \"1\" as malign and \"0\" as benign (malign is assigned to 1 because our goal is to predict malign tumors with the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Break up the data and look at correlations\n",
    "\n",
    "Split up the data into 3 datasets for the \"mean\", \"standard error\", and \"worst\" statistics on each predictor variable.\n",
    "\n",
    "---\n",
    "\n",
    "NOTE: The difference between standard error and standard deviation is subtle:\n",
    "\n",
    "A new observation has about a 95% chance to be within **2 standard deviations** of the sample mean.\n",
    "\n",
    "The sample mean has about a 95% chance to be within **2 standard errors** of the real population mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function that subsets the data to the columns indicating the\n",
    "# mean, se, or wrong variable types\n",
    "def df_subsetter(df, suffix):\n",
    "    column_select = [x for x in bcw.columns if suffix in x]\n",
    "    bcw_subset = bcw[['id','malignant'] + column_select]\n",
    "    bcw_subset.columns = [x.replace(suffix, '') for x in bcw_subset.columns]\n",
    "    return bcw_subset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Examine correlation matrices for the 3 datasets\n",
    "\n",
    "Look at the correlations between variables for each of the subset datasets, excluding the id column.\n",
    "\n",
    "1. The mean columns subset\n",
    "2. The standard error columns subset\n",
    "3. The \"worst value\" columns subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Look at correlations between mean, standard error, and worst within variable\n",
    "\n",
    "Look at the correlations between each single variables mean, se, and worst value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function that prints the variable name, subsets the data to just\n",
    "# be columns that have those variable names, and print out the\n",
    "# correlation between the variables\n",
    "def variable_corr_printer(df, varname):\n",
    "    print varname\n",
    "    df_sub = df[[x for x in df.columns if varname in x]]\n",
    "    print df_sub.corr()\n",
    "    print '--------------------------------------------\\n'\n",
    "\n",
    "# get the variable names without the _mean, _se, _worst suffixes and\n",
    "# remove duplicate names by filtering\n",
    "varnames = [\n",
    "    x.replace('_mean','')\n",
    "    for x in bcw.columns\n",
    "    if x not in ['id','malignant']\n",
    "    and '_se' not in x\n",
    "    and '_worst' not in x\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use seaborn's pairplot to visualize relationships between variables\n",
    "\n",
    "Look at the data using seaborn's `pairplot()` function. The hue will be the class variable \"malignant\". The variables will be the other columns excluding, of course, the subject ID column.\n",
    "\n",
    "Most of these predictors are highly correlated with the \"class\" variable. This is already an indication that our classifier is very likely to perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the seaborn style to have a white background\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# This function does a pairplot across your variables with the color\n",
    "# set as the outcome \"malignant\" class variable\n",
    "def bcw_pairplotter(df, variables, sample_frac=0.3):\n",
    "    # sample_frac lets you specify an amount of the data to sample for the plot.\n",
    "    # this speeds up the function which can take awhile with the full data.\n",
    "    \n",
    "    # get the number of rows/data points:\n",
    "    rows = df.shape[0]\n",
    "    \n",
    "    # get downsample indicies for the data, if specified\n",
    "    if sample_frac < 1.0:\n",
    "        sample_inds = np.random.choice(range(0,rows), \n",
    "                                       size=int(round(rows*sample_frac)), \n",
    "                                       replace=False).astype(int)\n",
    "    \n",
    "    # make the pairplot for the variables:\n",
    "    pairs = sns.pairplot(df.iloc[sample_inds, :], \n",
    "                         vars=variables, \n",
    "                         hue=\"malignant\", \n",
    "                         palette=sns.xkcd_palette(['windows blue', 'amber']))\n",
    "\n",
    "\n",
    "# get out the column variable names to put into the pairplotter function\n",
    "colvars = [x for x in bcw_mean if x not in ['id','malignant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Plot the mean data subset with the pairplotter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Plot the standard error data subset with the pairplotter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Plot the worst value data subset using the pairplotter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the performance of kNN classifiers on the data using cross-validation\n",
    "\n",
    "Let's see how the kNN classifier performs on the dataset with cross-validation.\n",
    "\n",
    "We are going to set some parameters in the classifier constructor. Some clarification below:\n",
    "\n",
    "1. **n_neighbors** specifies how many neighbors will vote on the class\n",
    "2. **weights** uniform weights indicate that all neighbors have the same weight\n",
    "3. **metric** and **p** when distance is minkowski (the default) and p == 2 (the default), this is equivalent to the euclidean distance metric\n",
    "\n",
    "Load scikit's handy cross-validation module.\n",
    "\n",
    "The `cross_validation.StratifiedKFold()` function will return cross-validation indices which you can use to subset your data in a for loop that runs the model and tests it.\n",
    "\n",
    "The **stratified** version of cross-validation ensures that there are equal proportions the predicted class in each train-test fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to crossvalidate accuracy of a knn model acros folds\n",
    "def accuracy_crossvalidator(X, Y, knn, cv_indices):\n",
    "    \n",
    "    # list to store the scores/accuracy of folds\n",
    "    scores = []\n",
    "    \n",
    "    # iterate through the training and testing folds in cv_indices\n",
    "    for train_i, test_i in cv_indices:\n",
    "        \n",
    "        # get the current X train & test subsets of X\n",
    "        X_train = X[train_i, :]\n",
    "        X_test = X[test_i, :]\n",
    "\n",
    "        # get the Y train & test subsets of Y\n",
    "        Y_train = Y[train_i]\n",
    "        Y_test = Y[test_i]\n",
    "\n",
    "        # fit the knn model on the training data\n",
    "        knn.fit(X_train, Y_train)\n",
    "        \n",
    "        # get the accuracy predicting the testing data\n",
    "        acc = knn.score(X_test, Y_test)\n",
    "        scores.append(acc)\n",
    "        \n",
    "        print('Fold accuracy:', acc)\n",
    "        \n",
    "    print('Mean CV accuracy:', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Cross-validate accuracy for a kNN model with 5 neighbors on the mean data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Cross-validate accuracy for a kNN model with 1 neighbor on the mean data subset\n",
    "\n",
    "As you can see the mean cross-validated accuracy is very high with 5 neighbors. \n",
    "\n",
    "Let's see what it's like when we use only 1 neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Cross-validate accuracy for a kNN model with 5 neighbors on the standard error subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Cross-validate accuracy for a kNN model with 5 neighbors on the worst value subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot the kNN prediction boundary\n",
    "\n",
    "Even with 1 neighbor we do quite well at predicting the malignant observations.\n",
    "\n",
    "We will fit a kNN classifier with n_neighbors=5 using just **`nucleus`** and **`perimeter`** predicting the **`malignant`** class column.\n",
    "\n",
    "The plotting function below will plot the points and the boundary of where the classifier votes between malignant vs. benign classes. \n",
    "\n",
    "---\n",
    "\n",
    "Below is the helper function for plotting. All the sections are documented so you can walk through it and see how it works! (As usual, matplotlib code is not easy to read..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as cl\n",
    "\n",
    "\n",
    "# MOST OF THIS FUNCTION STUFF LIFTED FROM SCIKIT-LEARN EXAMPLE!\n",
    "# see:\n",
    "# http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#example-neighbors-plot-classification-py\n",
    "\n",
    "def knn_boundary_plotter(df, var1, var2, classvar='malignant',\n",
    "                         nn=3, granularity=50.):\n",
    "    \n",
    "    # Subset the data to just the two variables to plot and the class variable\n",
    "    df = df[[var1, var2, classvar]]\n",
    "    \n",
    "    # reset the index in case this matters..\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # get the point colors from a seaborn built in palette\n",
    "    point_colors = sns.xkcd_palette(['windows blue', 'amber'])\n",
    "    \n",
    "    # set the mesh colors to be more \"faded\"/brighter versions of the point colors\n",
    "    mesh_colors = ['#8FCCFF', '#FFED79']\n",
    "\n",
    "    # the 'pcolormesh' matplotlib function requires we convert the mesh colors into a \n",
    "    # 'colormap'\n",
    "    colormap = ListedColormap(mesh_colors)\n",
    "\n",
    "    # fit a knn on the data with the nearest neighbors number passed into the function\n",
    "    knn_mod = KNeighborsClassifier(n_neighbors=nn)\n",
    "    knn_mod.fit(df[[var1, var2]].values, df[classvar].values)\n",
    "\n",
    "    # get the minimum and maximum values for each of the predictor variables\n",
    "    v1_min, v1_max = np.min(df[var1]), np.max(df[var1])\n",
    "    v2_min, v2_max = np.min(df[var2]), np.max(df[var2])\n",
    "\n",
    "    # get the range of each variable\n",
    "    v1_range = v1_max - v2_min\n",
    "    v2_range = v2_max - v2_min\n",
    "\n",
    "    # set up the min and max ranges of the axes of the plot\n",
    "    # I add a buffer here (1/15th of the range) so no points are on the axes\n",
    "    buffer_denom =  15.\n",
    "    \n",
    "    x_min = v1_min - (v1_range/buffer_denom)\n",
    "    x_max = v1_max + (v1_range/buffer_denom)\n",
    "    \n",
    "    y_min = v2_min - (v2_min/buffer_denom)\n",
    "    y_max = v2_max + (v2_range/buffer_denom)\n",
    "\n",
    "    # use the numpy meshgrid function to make a bunch of points across the range\n",
    "    # of values.\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, (v1_range/granularity)),\n",
    "                         np.arange(y_min, y_max, (v2_range/granularity)))\n",
    "    \n",
    "    # Predict using the knn model on all the meshgrid points. This will let us see\n",
    "    # the knn boundary of where it predicts between one class and another!\n",
    "    Z = knn_mod.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # get out the values of our two predictors and class target variable\n",
    "    v1_points = df[var1].values\n",
    "    v2_points = df[var2].values\n",
    "    class_colors = df[classvar].values\n",
    "\n",
    "    # point size of 70 seems to work well\n",
    "    point_sizes = 70\n",
    "\n",
    "    # Set the figure size to be big enough to see stuff\n",
    "    plt.figure(figsize=[11,9])\n",
    "    \n",
    "    # Plot the background colormesh colors, showing the decision boundary\n",
    "    # of the fit k nearest neighbors algorithm:\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=colormap)\n",
    "\n",
    "    # Plot the actual points of the 2 predictor variables\n",
    "    plt.scatter(v1_points, v2_points, c=point_colors, s=point_sizes)\n",
    "    \n",
    "    # set the axis limits:\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    \n",
    "    # Add the labels corresponding to the variables and a title\n",
    "    # (I remembered this time, Sam!)\n",
    "    plt.xlabel(var1, fontsize=20)\n",
    "    plt.ylabel(var2, fontsize=20)\n",
    "    plt.title('kNN='+str(nn)+' model predicting '+classvar+' with '+var1+' & '+var2+'\\n',\n",
    "              fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Use the boundary plotter function to plot area vs. symmetry using the mean value data and nn=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Use the boundary plotter function to plot area vs. symmetry using the mean value data and nn=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Use the interactive widget to explore the effects of changing the knn values\n",
    "\n",
    "Feel free to change the axis variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_axis_var = 'area'\n",
    "y_axis_var = 'symmetry'\n",
    "\n",
    "def knn_area_symmetry_slider(nn):\n",
    "    knn_boundary_plotter(bcw_mean, x_axis_var, y_axis_var, nn=nn)\n",
    "    \n",
    "widgets.interact(knn_area_symmetry_slider, \n",
    "                 nn=widgets.IntSlider(min=1, max=101, step=1, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What is the effect of increasing/decreasing the neighbors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 What could be wrong with using accuracy as your measure of performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Examine more paired variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Explain changing the number of neighbors in terms of bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
